19/06/20
The Importance of Syntax

Before jumping into the sea of language design, I didn't care much for syntax. Sure, I had some pretty strong opinions on how I wanted my code to look. However, most of those
where related to variable naming convention, indentation and languages that force a particular, \*cough\* OOP esque, style. Although I became more aware of how important syntax
and naming is after starting to watch <a href="https://handmadehero.org/">Handmade Hero</a>, it was first when I began writing parsers that it dawned on me. I was writing the
documentation for this horrible ad hoc syntax that puzzled, not only the people I showed it to, but also myself. It was not only hard on the eyes, but also a nightmare to 
parse. Afterwards I designed the language with parsing in mind, adding keywords and subtle details to remove unnecessary ambiguity. This was all fine and dandy for parsing, but
it also became apparent that some parts of the language were much clearer and more natural when conveyed in a syntax that was not as easy to parse. It again became apparent 
that oversimplifying can, more often than not, add more complexity. An example of this is how *if* statements are parsed. One option would be to define an *if* statement as
the keyword *if*,  followed by an expression and then a statement. This is the definition I find to be the easiest to parse, and it may seem alright. However, it does introduce
some inconsistency.
```
// if expression statement allows this
if a == b DoStuff();
// but also this 
if (a == b) DoStuff();
```
Now that may not seem like a huge problem, although it does add some visual inconsistency across a code base if the two styles are mixed. The problem lies in how that
definition of an *if* statement compares to a "for" loop. Take a C style *for* loop. What would be a reasonable definition of how this *for* loop should look?
Maybe the keyword *for* followed by a variable declaration, then an expression as the condition, a statement as the increment step (since we are not crazy enough to allow 
assignment to be an expression) and a statement to execute every loop. Something like this:
```
// for statement expression statement statement
for int i = 0 i < 10 i += 1 DoStuff();
```
Well that looks like a mess. Lets add some parentheses and semicolons to separate the individual elements.
```
// for (statement; expression; statement) statement
for (int i = 0; i < 10; i += 1) DoStuff();
```
What we just did will not help the parser at all, but it is clearly more readable. Now, stop for a moment and think about how we treated the *for* loop differently from
the *if* statement. The *for* loop needed some additional "fluff" to be readable, whilst the *if* statement did not. This may seem more like stating trivia than a
glaring problem, but consider what a beginner might think of this. An obvious question would be "can I remove the parentheses around the *for*, like I can with the *if*"?
The obvious answer would be "no, you can't", and that would be because the *for* requires parentheses, but the *if* does not. The only reason you may see parentheses in an
*if* statement is because an expression surrounded by parentheses is still just an expression, and the *if* requires only an expression after the *if* keyword. So what?
That seems like more of a problem with how the syntax is taught than an inherit problem with the syntax itself. That may be the case, but I would argue that the syntax design
should take into account and eliminate such misconceptions. Why is that important? Lets look at assembly.
\n
\n
I don't know about you, but I have a hard time understanding what a program does when written in assembly. More often than not do I end up having to go line by line and rewrite
the assembly as "math with arrows". I usually have no problem with writing, but reading assembly is always a pain. Why is that? It may be because there are no operators,
usually few variable names and a general lack of abstraction. Assembly is great, don't get me wrong, but it is horrible when it comes to quickly identifying what a piece of
a program does and understanding how it works. Machine language is even worse, were you often have to resort to tables of opcodes to understand where the instructions are in a
stream of 1's and 0's, what they do and how they affect each other. From what I've gathered, higher level languages were designed to mitigate this, **to make code more 
readable and easier to understand**. Then, if that is the reason why higher level languages exist, why do we keep making languages that are hard to read or have quirks
that prompt questions? The reason for this is the same for any language, even natural languages, and that is: "language design is hard and is often driven more by convention
and tradition than what makes the most sense".
\n
\n
Another factor that should not be neglected is that people often say that syntax does not matter, semantics do. Even the creator
of the programming language Jai has stated this numerous time in his <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO">videos</a> 
about the language. This may not be true, at least not always, but I believe syntax
is as important as semantics. The reason? The syntax is what we use to convey the semantics, and if one does not fully understand the syntax, one cannot possibly understand
the actual semantics. This is true both for programming languages and natural ones, and is the reason why "double speak" exists. An example of this would be answering the
sentence "Have you eaten my lasagne", with "I ate my sandwich". This answer can both be the truth and a lie, depending on how one interprets it. The answer could be interpreted
as "I ate my sandwich" with no additional information, but may be interpreted as "I did not eat your lasagne, only my sandwich" given the context. The answer could be remedied
by adding an "only", but still goes to show how the same sentence can convey different meanings, if not crafted carefully. I therefore believe the best way to design a language
is by **considering how a concept could be expressed, how that expression could be misinterpreted and how the concept and expression could be changed to mitigate this**.
\n
\n
When designing Otus I have tried to take this into account and have ended up sinking hours into designing the *for* loop in this language. The challenge with *for* loops is
that there is often a sharp distinction between how people think of them and how they are used, especially in C. The most common explanation, I find, for a *for* loop is a
loop that executes a piece of code N times. This explanation leaves out all *for each* and *for as long as* style for loops, which I find to be more common and useful. One
could kind of fix this problem by introducing new loop constructs and restricting their behaviour, but I have found that a looser definition of a *for* loops could be more
useful. I would define a *for* loop along the lines of "a statement before a block of code that is will execute the block repeatedly as long as a condition holds, with the 
ability to specify a statement that is executed before the block, and one that is executed after every repetition and before the condition is checked, both statements are 
scoped to the block". Now definition is definitely wordy, and a bit loose. This might well be a stupid way to describe a *for* loop, but I think it does a better job of
synergizing the syntax and semantics, and more closely reflects how *for* loops are actually used most of the time. I have therefore decided to double down on this and have
ultimately decided that the language **will only feature one looping construct**, which is currently called a *for* loop. This loop behaves exactly like the definition I 
proposed, and was initially expressed like this:
```
// for (statement; expression; statement) statement;
for (i : int = 0; i < 10; i += 1) DoStuff(); // i : int = 0 is a variable declaration, equivalent to int i = 0 in C
```
Now, it is somewhat stupid to name this loop *for*, but I didn't find another name that would be a better fit. There are however some nasty problems with this, aside from the
name. The problems do not lie in the definition or syntax, per se, but rather the weird surprises this type of loop can create.
```
// This is a do {} while (0) in C
for (; true; break) DoStuff();
```
After discovering this, and some other quirks, I tried rewriting them with an additional restriction on the loop. An example of this would be the rewritten *do while*:
```
// for (variable_declaration; expression; assignment) statement;
for (; true; )
{
    break;
}
```
The intention of this loop is still not as clear as *do while*, and my decision of removing every loop construct except *for* may have been idiotic, but **I believe it might 
lead to a syntax that more closely resembles what is actually going on**. Again, oversimplifying something may often lead to more complexity. But if no one dares to do 
something that might be stupid, how will we ever evolve?
