<!doctype html>
<html lang="en">
<head>
<title>Otus Programming Language</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta charset="utf-8"/>
<meta name="description" content="Documentation and useful information about the Otus systems programming language. The Otus language aims to be low level and &quot;simple but powerful&quot;"/>
<meta name="author" content="Simon DoksrÃ¸d"/><meta name="robots" content="index,follow"><link rel="stylesheet" type="text/css" href="style.css" title="main">
<script src="generated_script.js"></script>
</head>

<body>
<div id="page_container">
<div id="header">
<img src="Otus.svg" alt="Otus logo" id="logo"/>
<ul id="navbar">
<li><a href="#about"><b>About</b></a></li><li class="navbar_vl">|</li>
<li><a href="#docs"><b>Docs</b></a></li><li class="navbar_vl">|</li>
<li><a href="#log"><b>Dev Log</b></a></li><li class="navbar_vl">|</li>
<li><a href="https://github.com/Soimn/Otus"><b>GitHub</b></a></li>
</ul>
</div>

<div id="content">

<div id="about_tab">
<h1>The Otus programming language</h1> The Otus programming language aims to be a <i>"simple but powerful"</i> alternative to C, and takes heavy inspiration from languages such as <a href="https://odin-lang.org/"> Odin</a> and <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO"> Jai</a>. The current goal of the language is to be: <ul> <li><b>Clear and concise</b>, to ease readability</li> <li><b>Low friction</b>, to ease development of complex software</li> <li><b>Minimalistic and extensible</b>, to allow arbitrary levels of abstractions</li> </ul> </div>

<div id="docs_tab">
</div>

<div id="log_tab">
<div id="log_intro">
This is a collection of articles in a log-esque format that try to describe the problems I have encountered while designing the language and compiler.
</div>
<div class="log_title_minimized id200617" onclick="window.location.hash='#log@id200617'"><a href="#log@id200617">Import Declarations</a></div><div class="log_date_minimized id200617">2020/06/17</div>
<div class="log_content_minimized id200617">
Header files and dealing with cyclic imports has never really bothered me (except when I first learned C++ without knowing why header files existed in the first place). I was therefore quite puzzled when Jonathan Blow presented header files, along with C++'s arrow operator, as major issues with C++ in his video <a href="https://youtu.be/TH9VCN6UkyQ">about a better programming language for games</a>. At that time, I saw the benefit of removing header files, but also, in my opinion, a huge drawback. Include directives in C declare a dependency, but also serve as a guide as where to look for the implementation of anything in a given file. The implementation could of course be hidden behind N nested imports (N being a significantly large number), but you at least know that for any given identifier, that is not part of the C language, you will always find the implementation further up the file, or in one of the imported header files. This promise is important for understanding foreign code and is broken by the use of multiple translation units (non-unity build), and the removal of the requirement for every file to import it's dependencies. Now, I'm not saying there is a problem with Jai because it does not have any header files (as it seems to only remove the forward declarations, not import dependencies), but it got me thinking. <br> <br> Import declarations should, in my opinion, declare a dependency on a file and allow access to all global declarations of that file in the current file's global scope. There is however a problem with this. If the import declaration imports everything in the target file, it will inevitably be impossible to hide the implementation of something behind anything larger than a procedure, or struct. This is a problem, since a lot things in programming benefit from "helper functions" that should only be visible to the to the intended users. Helper functions that are globally visible could lead to bugs due to use outside the intended scope of the function, and in the <a href="http://number-none.com/blow/blog/programming/2014/09/26/carmack-on-inlined-code.html">words of John Carmack</a>: <i>"Most bugs are a result of the execution state not being exactly what you think it is"</i>. Importing files should therefore be somewhat selective. Jai solves this by adding the concept of a file- and export scope. Every declaration in a file is local to that file (in file scope), unless it is exported. This seemed like a good idea, along with the use of compiler directives to indicate whether a block of code is exported or not. The only issue I have with Jai's import behaviour is that an import declaration seems to affect other imported files as well (similar to how textual imports sometimes break the "dependency promise" of each imported file). A problem with enforcing this "dependency promise" is that it adds a lot of redundant import declarations to common files and unnecessary visual clutter. However this could be solved by allowing the programmer to specify a group of files that should be implicitly imported in all source files. <br> <br> Then there is the question of how to deal with libraries. Ginger Bill's <a href="https://odin-lang.org/"> Odin</a> has in this case been an example of how I personally think libraries should not be handled. This might be due to the fact that I don't use libraries since I despise having code in my codebase that I have not written, or fully understood myself. However, I think the way Odin requires every file to specify a parent package is damaging to the project. This is due to two issues I have with the approach: <ul> <li>being <u>mandatory</u> in every file, it introduces additional unnecessary visual clutter</li> <li>it might encourage enforcing stricter barriers, than optimal, between functionality in a codebase</li> </ul> The first issue is a trivial one, but the second is, in my opinion, a great flaw with the language. Now, I'm not saying code should be an entangled spaghetti mess, but I am definitely advocating that overly modularizing code is akin to trying to build a fortress from breadcrumbs. It is not necessarily bad to separate part of a code base in different files, or even libraries, but it is truly damaging to the code base when those barriers are encouraged and used haphazardly. Packages in Odin seem to only be used in distribution and import of several files as one. Allowing the programmer to import both files and directories, would in my opinion achieve a similar result, without the need for the concept of a package. Odin does however do a few things I like, namely "library collections", and import namespacing. In Odin you are able to prefix an import path with a label which declares which "library collection" that file is a part of. Adapting this to work with the file system instead could yield a sort of prefix path label, where the label is a sort of "shorthand" for an absolute path. This is useful since it explicitly declares where the compiler should look for a file without needing to specify the full path, instead of using a list of search paths as in C. Import namespacing is also a step in the more explicit direction, as giving each imported declaration a mandatory prefix could both fix name collisions and increase readability. <br> <br> Import declarations in Otus will therefore be able to import single files or every source file in a directory. A prefix "name:" label could be added to change the search path from relative to absolute, with the path bound to the label being prepended to the import path. An alias, or namespace, can also be specified, which hides the imported declarations behind a "alias." barrier. Every file needs to import what it uses, except for what is chosen to be globally imported. <br> <br> EDIT:<br> After much thought it seems like I was too narrow minded when writing this, as it seems like the rules I made are more fit for libraries than files. <br> <br> I have made a habit of separating parts of a program into several files based on the general functionality provided by that part of the program. These files are not, and should not be treated as, encapsulated pools of code, but rather a focused view of the main file. I therefore elected to embrace this and design the import system around it. Stealing the nomenclature from Jai and Odin, I have split importing into three separate concepts: package importing, file loading and foreign library importing. <br> <br> The import system described in this article/log has been renamed to package importing, but still functions exactly the same, except for the imported declaration always being in a different namespace from the importer. Packages are normal source files with the addition of a package declaration ("package NAME") on the top of the file and every non-overridden link name being prepended with the package name <br> <br> File loading on the other hand is an "entirely new" concept which basically amounts to textual importing in C. Loading works exactly the same as importing, except that the link names are not changed and the namespaces of the two files are merged, instead of being kept separate <br> <br> Foreign library importing is just a mechanism to allow for static linking with C libraries, and allows the programmer to use identifiers instead of strings to refer to libraries when writing procedure "prototypes". </div>
<div class="log_title_minimized maed200614" onclick="window.location.hash='#log@maed200614'"><a href="#log@maed200614">Motivation and Early Development</a></div><div class="log_date_minimized maed200614">2020/06/14</div>
<div class="log_content_minimized maed200614">
Hi. I am Simon. A sometimes humble game and engine developer living in Norway, who apparently decided to stack mountains on top of each other to reach Mt. Olympus. The mountains being code and Olympus being an actual working compiler. Before recapping half a year of development, a bit of background. <br> <br> Around Christmas time last year, I grew a bit frustrated with C and C++. At the time I was working on my Nth iteration of a game engine, using a small subset of C++, and wanted to rewrite my MIN/MAX macros as proper functions to allow for type checking. Little did I know that the frustration of there being <u>no</u> implementation of MIN/MAX in C or C++ that I would be satisfied with. I tried out different versions of templated functions, which I despised, and eventually went on to scour for compiler specific C extensions. While searching I continuously chanted that "there must surely be a proper way to implement MIN/MAX functions in C". Eventually I stumbled upon "generic selection macros" in C. Compile time selection of expressions based on type seemed to be the solution I was looking for. However, there was still a slight problem with the approach. Apparently MSVC does not properly support any new (new being post 90's) features of the C language, making generic selection a no go. <br> <br> What I wanted from C, or C++, was the ability to write, or generate, a maximum of <u>three</u> functions (int, uint, float) and have the result cast to the correct common type. Now, this may seem like a negligible problem. Surely generating a small number of functions, or even using a C like naming scheme, would not harm the resulting program significantly. It was not this small scale issue I was troubled with, but rather the fact that the language prevented me from expressing what I wanted to do, without a lot of cruft. All the problems I had with C and C++, most of them being with C++, accumulated to critical mass right around the time I started watching <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO"> Jonathan Blow's</a> videos on his new language Jai. Jai seemed like a godsend at the time. I fondly remember working on the rendering API for my game engine while watching one of his compiler streams. When working on the rendering API I found myself wanting a way of "unpacking" structs. This would allow for standardizing common elements in structs, without needing to access the members via an intermediary variable. I was about to suggest this "struct unpacking" idea, when I realised that a superior version was already implemented in Jai (the using statement). It seemed however that Jai would release way off in the future, and I could not wait that long, so I decided to make my own language. <br> <br> The language started as an extension to C with added metaprogramming and altered casting rules. The syntax was similar to C, with some added quirks due to type inference, multiple return values and improved templates, and functioned almost exactly like C. This introduced some problems, as I had at that time never written a parser (or any other part of a compiler), and the many quirks of C syntax, including my own additions, seemed like too much. I therefore decided to alter the syntax a bit, changing it to look more like Jai. Along the way I also came up with some (I would say "interesting") ideas, and the syntax ended up being a hot mess. After several renditions due to aesthetics and holisticity, I arrived at a syntax similar to Jai, but different in a few subtle ways. <br> <br> I planned on using this language up until Jai released and then switch, but as the project grew, I felt like I had arrived at a crossroads. One option would be to make a throwaway language and continue on engine development, another would be to pause the development of my existing projects and develop a proper language. This dilemma lead to a lot of frustration and hopelessness as I did not see myself being able to finish both the engine and the language in any reasonable time frame. However I did not like the idea of making a compiler for a throwaway language either. After working on a parser for the language I also found myself a bit repelled by the complexity of it. By extension I also found myself displeased with the complexity of Jai, as my language was supposed to be a simpler version of it (so that I could manage the development of it). At the same time I was watching a lot of language design talks, and stumbled upon <a href="https://odin-lang.org/"> Odin</a>. Odin seemed to have taken a similar route to my language, simplifying Jai. However, I still found Odin to be a little too complex, and after developing the parser in C, I found that I really did not need much to code effectively. I therefore decided to throw everything I did not deem as necessary out the window, and strive to make the language as simple as possible. However simplifying the language too much could, strangely enough, lead to more complexity, as evident with machine language. I therefore adjusted my aim towards "simple but powerful", by reducing the moving parts of the language to a few powerful constructs that could be used directly, or to build new abstractions. <br> <br> Lately I have been redesigning the language's syntax and semantics, as I found that a lot of the "unique" concepts I had introduced were not useful enough to outweigh the added complexity. One of those concepts was "infix function calling". This was a purely syntactical alternative to calling functions, allowing for operator-like functions with no semantic difference from a regular call. 
<div class="code">
<span class="code_comment">// Normal function call</span>
Inner(a, b);

<span class="code_comment">// Infix call</span>
a <span class="code_literal">'Inner'</span> b;

<span class="code_comment">// Prefix call</span>
Length<span class="code_literal">' a;

// Postfix call
a '</span>Length;
</div>
 This seemed like a good idea, since the language does not have operator overloading. It proved however to only be useful in very specific circumstances (like vector operations), that could often be solved by a more useful construct. I have also been sketching out the specifics of metaprogramming in the language, and have learned, by a lot of trial and error, that an integral feature of the language, such as metaprogramming, should <u>not</u> be retrofitted to an existing language, but rather built in tandem with it. <br> <br> And that is most of the early development of this language summarized, with most of the frustration, cuss words, stupidity and details removed for ease of reading. The language is still far from finished, especially since I decided to scrap months of work, but it seems like this project is feasible, and would possibly prove to be useful to at least one person. </div>
<div class="log_title_minimized m200727" onclick="window.location.hash='#log@m200727'"><a href="#log@m200727">Metaprogramming</a></div><div class="log_date_minimized m200727">2020/07/27</div>
<div class="log_content_minimized m200727">
Metaprogramming has been the driving force behind the language design decisions since the very beginning. Starting from C as a base, almost every feature added and removed was done to make metaprogramming either easier, cleaner or more powerful. Since metaprogramming has been such a central part of designing the language it was important to get it right. This would, however, prove difficult. <br> <br> PS: this article may seem somewhat nonsensical at some points, and this is due to the fact that I am still not familiar enough with metaprogramming, even after several months of work, to explain it as simple as the concept really is. <h1>Early Development</h1> When I first decided to create a compiler, I was actually working on a game engine, so I didn't want to waste a lot of work designing a language that I might never use. I therefore thought it would be best to stick with C as the base language, and then write a custom compiler with metaprogramming features. But after discovering how horrible C was to parse, and how much worse it would be if I were to add syntax for type inference and multiple return values, I ended up deciding to create my own language. <br> <br> At first this language closely resembled C, but even though I removed a lot of craziness in the syntax, it was still an ugly parse. And after a phase of several complete syntax redesigns, I ended up with a syntax that landed somewhere in between <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO"> Jai</a> and <a href="https://odin-lang.org/"> Odin</a>. When I had settled on a syntax, I began work on the parser. At this stage I thought a working compiler would be right around the corner, and I couldn't be more wrong. As I wrote the parser and began work on semantic analysis and type checking, I started learning a lot more about language design. This made me a lot more conscious about how syntax affects the perception of semantics, and how the semantics would influence the metaprogramming. This made me realise that my approach to designing the language had been all wrong. Instead of designing a syntax for C like semantics with metaprogramming as an afterthought, I should rather design the syntax, language semantics and metaprogramming facilities in unison. This may seem obvious, and it really is, but as primarily a game developer it took me a long time to realize this. <br> <br> The decision resulted in me scrapping the parser and working on designing the language for a few months. During this period, the goals of metaprogramming in the language changed quite often. At first the goal was to provide some simple way of modifying the AST in the source code, and would then change to the compiler being implemented as a library where an external program would be able to monitor and modify the compilation. Using a somewhat bodged version of the hypothetico-deducitve method, and a lot of experimentation, I ended up with a base language that was somewhat complete, and a specification for how the metaprogramming should work, and where the complexity would lie. It was also around this time I seriously considered quitting. This was mostly because the task of creating the system that I had designed seemed immensely difficult, but as I had already sunken probably a couple hundred hours into the design of this language I didn't want to stop and let all that work go to waste. <br> <br> Thus the premise of this article: <b>a short summary of my attempt at tackling these problems, and the solution I came up with.</b> <h1>Internal vs. External</h1> One of the first problems I encountered was purely a design problem. It did have a lot of impact on the inner workings of the compiler, but the implementation was not the problem, the usability and clarity was. The problem had to do with whether most, or all, of the metaprogramming should be done within source, from an external program or a combination of the two. Internal metaprogramming, as I call it, is present in a lot of languages today, and is the ability to modify the AST, and other qualities of a program, from within the source code. External, on the other hand, is the ability to modify the program from a separate process. If flexibility is the end goal, it may seem like an obvious choice to support both. But, if an equally important goal is to keep the language sane and simple, the choice becomes a bit hairy. There are three main problems with both mixing, and choosing one or the other, namely: local reasoning, availability and evaluation order. <h2>Local Reasoning</h2> In essence, local reasoning is the ability to understand a piece of functionality from information that is "locally available". Meaning that the reader does not necessarily need to understand how an entire program works, in order to reason about a given fragment of the functionality. Enabling local reasoning is immensely important to maintain code readability, and any feature that detracts from this would severely damage the language. Ensuring that metaprogramming would not hinder local reasoning was therefore a very high priority. Now, what does this have to do with internal vs. external metaprogramming? You may have guessed this already, but something being "external" implies that it is further away from the "core", than something "internal". This would make it seem that internal metaprogramming would benefit local reasoning more than external. However, there is one important caveat. An internal metaprogram that is separated from the code it modifies by file, or even in the same file, but as a separate declaration, is almost indistinguishable from an external one, given the same toolset. To truly aid local reasoning, it should be possible to implement the metaprogram in the exact place that it modifies. Internal metaprogramming that enables this would therefore be most beneficial from a "local reasoning" standpoint. <br> <br> PS: this form of internal metaprogram that is implemented "inline", i.e. the same place it modifies, is present in the programming language <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO"> Jai</a> with the "body_text" directive. This compiler directive enables the programmer to write code that generates an AST that replaces the body of the surrounding procedure, or struct. There is also the "insert" directive, which allows the programmer to arbitrarily insert code snippets in place. <h2>Availability</h2> One of the problems with metaprogramming in most languages, is that normal functionality is often unavailable. Take for example utility procedures like max, min and clamp. If these procedures are implemented in the same program that a metaprogram is working on, they may be unavailable for use in the metaprogram. Now, there are many languages that do allow metaprograms to access this functionality, but they are often either interpreted or dependent on declaration order, which my language is most certainly not. There are however a few solutions to this problem. An external metaprogram can easily access the source code of the program it is manipulating. However, some of this functionality may depend on, or be slightly altered, by the metaprogram, which means that including the raw source code may result in unwanted behaviour, or down right fail to compile. As opposed to external metaprograms, Internal metaprograms are free to use any functionality that does not depend on the code they are modifying. This does however require a lot of dependency solving, and may require some nasty hacks, like searching for procedures that are supposed to modify the compilation of the entire program only be name, since type information may not be available at that time. <br> <br> <h2>Evaluation Order</h2> Now, the last of the major problems with deciding between internal and external metaprogramming: evaluation order. This simply boils down to the fact that it is easier to handle compilation in an arbitrary order when the functionality that is in charge of modification is not part of the equation. Meaning that external metaprograms are cleaner in this regard, since the compiler does not need to find (without type information) the metaprograms that modify the entire program. <h2>Internal and External</h2> If nothing else, you should now know that internal metaprograms seem to be better at enabling local reasoning, external are cleaner when it comes to evaluation order and both internal and external are a bit fuzzy with availability. In the end, what seems to be the best option is a mix between the two. You may now be screaming: "just take the good parts of both and combine them, you fool", and that is, in fact, what I too shouted when reading my notes. Internal metaprogramming, that is "in place" (i.e. beside the code it modifies), would be responsible for local transformations, while external would deal with program wide transformations. This enables local reasoning with local transformations, and eliminates problems with evaluation order. Availability is however still a problem. Internal metaprograms would not suffer from this, since they no longer operate program wide, but the problem with availability for external metaprograms is still present. One way of somewhat remedying this is to allow the external metaprogram to run compiled procedures that do not affect global state. Alternatively, it may be beneficial to allow the metaprogram to run the compiled bytecode in a sort of "sandbox", and allow it to conditionally commit the results to the programs data section. Anyway, I ended up choosing external metaprogramming for "coarse-grained" modification, and internal for "fine-grained" modification. <h1>Freedom</h1> A major problem with designing external metaprogramming API is user freedom. I don't see a point in supporting metaprogramming if you are only able to change a small part of the program in question. I have therefore strived to enable as much freedom as possible when designing the language and metaprogramming facilities. However, the problem with making a system more free, is that it simultaneously introduces a lot more points of failure. Not only this, but there are a lot of hacks used by compilers that are impossible to leverage when a user is able to change several parts of the compilation process. <h1>Miscellaneous Problems</h1> <h2>Metaprogram notes</h2> To enable selective exclusion from, or application of, program wide rules, there must be a way for the source code to communicate with the metaprogram. This can be done in several ways, but I have opted to use "metaprogram notes". These notes are a combination of an identifier and zero or more expressions as arguments. Currently they are represented in the syntax as an @ followed by an arbitrary identifier, and optionally, a list of expressions delimited by commas and surrounded by parentheses. While the definition of a note is clear, I have yet to decide where exaclty these metaprogramming notes can be left in the source code, whether they applied to any expression or statement, or if their use is restricted to declarations. A problem that illustrates the consequences of this decision is "@attribute a = b". Does the attribute apply to the assignment statement as a whole, or only the left hand operand? If attributes are not applicable to expressions, this becomes a non problem, however, this decision also reduces a lot of freedom, since it eliminates the ability to express something like "a = @CrashOnOverflow (b + c)". An easy solution to this problem is to introduce another symbol for notes, "#", and state that "@notes" apply only to statements, while "#notes" apply to expressions. The problem with this solution is that is simultaneously introduces more complexity in the syntax, and removes the option for compiler directives, since there are no more easily accessible symbols to represent these. I have therefore thought about moving all compiler direvtives to keywords, however this results in not only an uglier syntax, but also further restricts the set of legal identifiers. After much thought I have concluded that keeping "#" dedicated to compiler directives, and make "@notes" apply to both statements and expressions, is the least horrible solution of the bunch. This does not only simplify the syntax and the corresponding AST nodes (which affects the complexity of external metaprogramming), but it also justifies some inconsistencies with the "precedence" of "@notes". This is useful because it allows the following transformation: 
<div class="code">
<span class="code_comment">// The name of a field is often the first thing you want to know                      (1)</span>
<span class="code_comment">// Secondly is the type of the field                                                  (2)</span>
<span class="code_comment">// Finally is how this field differs from every other field of that type (e.g. const) (3)</span>

<span class="code_comment">// By accepting that the "precedence" of "@notes" is wierd, the transformation</span>
<span class="code_comment">// from 3 1 2</span>
Structure :: <span class="code_keyword">struct</span>
{
	@SomeNote a: <span class="code_keyword">int</span>,
}

<span class="code_comment">// to 1 2 3</span>
Structure :: <span class="code_keyword">struct</span>
{
	a: <span class="code_keyword">int</span> @SomeNote,
}

<span class="code_comment">// Could be justified, which results in a more natural way of describing, and reading</span>
<span class="code_comment">// descriptions of, fields.</span>
</div>
 <h2>Breaking out from Structured Programming</h2> One of the primary goals of this languages is to be at least as low-level as C, while supporting the functionality to build arbitrarily high level abstractions on top of a few basic constructs. A major problem with achieving this goal is related to the concept of <a href="https://en.wikipedia.org/wiki/Structured_programming">structured programming</a>. C is mostly structured, but contains some unstructured constructs, such as "goto" and the "switch" statement. These constructs make it difficult to introduce new constructs, such as "defer" (defer execution of a statement until end of scope), without running into a lot of wierd edge cases. I have therefore opted to remove "goto", and the "switch" statement with jump labels, from the list of planned language constructs. Although this decision makes constructing the language a lot simpler, it also reduces a lot of freedom. There are several legitimate uses of "goto", which is either a pain, or damn right impossible, to leverage in a purely structured language. However, some of the most useful can be translated: 
<div class="code">
{
	<span class="code_comment">// A lot of code</span>
	did_succeed = SomeErrorProneProcedure();
	<span class="code_keyword">if</span> (!did_succeed) <span class="code_keyword">do</span> goto cleanup;
	<span class="code_comment">// A lot of code</span>
	did_succeed = SomeOtherErrorProneProcedure();
	<span class="code_keyword">if</span> (!did_succeed) <span class="code_keyword">do</span> goto cleanup;

	cleanup:
	<span class="code_comment">// Cleaup code</span>
}

<span class="code_comment">// Can be implemented in a structured way with the "defer" statement and the ability to break out of any block</span>

{
	<span class="code_keyword">defer</span> {
		<span class="code_comment">// Cleanup code</span>
	}

	<span class="code_comment">// A lot of code</span>
	did_succeed = SomeErrorProneProcedure();
	<span class="code_keyword">if</span> (!did_succeed) <span class="code_keyword">do</span> <span class="code_keyword">break</span>;
	<span class="code_comment">// A lot of code</span>
	did_succeed = SomeOtherErrorProneProcedure();
	<span class="code_keyword">if</span> (!did_succeed) <span class="code_keyword">do</span> <span class="code_keyword">break</span>;
}
</div>
 Eventhough some of the most useful patterns are transferrable, the language is still inferior in feature set to C by lacking these unstructured constructs. I therefore began thinking of ways to expand the freedom without introducing unstructured elements. One of the most obvious ways of doing this is to allow procedures to reference the calling scope, as demonstrated in on of Jonathan Blow's <a href="https://youtu.be/QX46eLqq1ps?t=1456">videos</a> on his language <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO"> Jai</a>. One could argue that this seems to violate the principles of structured programming, but it does not seem to introduce the the massive junkpile of problems that "goto" does, which is nice. To expand on this concept I began listing every related concept that did not seem to mess too much with the structuredness of the language. These are all operations on, or related to, scopes. <ul> <li>insert symbol</li> <li>remove symbol</li> <li>access symbol</li> <li>enter scope</li> <li>leave scope</li> </ul> Removal of symbols is problematic, since it introduces a lot of problems with invalidating already compiled code (and introducing a complex dependency solver into the mix is a lot more constly than removing the ability to remove a symbol), and entering a scope is just normal control flow. This leaves insertion and accession of symbols, and leaving scopes. Symbols that do not exist cannot be accessed, therefore accession is limited to already existing scopes, which means it is always refering to a parent scope. Insertion can also be restricted in a similar fashion by disallowing insertion of symbols into procedures and structs, because these may exist in a context where the symbol does not. Insertion of symbols into blocks (scopes inside procedures) can similarily be disallowed as the symbols is either already accessible from that scope, or it does not exist in the same context. Be eliminating sub-scopes, structs and procedures, this only leaves packages. Leaving a scope is already present in normal control flow, but could be expanded on by allowing "breaking" from any block, not just loops, and not just breaking to the immediate parent, but any parent block. This results in the following: <ul> <li>The ability to insert a symbol into a package</li> <li>The ability to access the symbols of any* parent scope</li> <li>The ability to leave any set of parent blocks</li> </ul> *may be restricted to any parent block of the caller <h2>Replacing the C preprocessor</h2> The C preprocessor is a powerful tool, some may say too powerful. But it does not change the fact that it is a useful part of the language/compiler. It does however introduce a bunch of problems with tooling, type safety and general readability. Replacing the preprocessor with something that does not have these flaws is therefore a reasonable goal. My proposal for replacing the preprocessor is "when" statements, and macros. When statements funciton as constant if statements, where the scope owned by the body of the statement "collapses" if the condition is true. Collapsing refers in this context to every symbol in a scope being transfered to the parent scope, and the removal of the collapsed scope. Macros are similar to when statements, where macros are procedures with no return value, where the body of the macro collapses when called. This enables the following code to be rewritten without using the preprocessor: 
<div class="code">
#<span class="code_keyword">if</span> _WIN32
#define X_MACRO(x) \
	x(<span class="code_literal">1</span>);          \
	x(<span class="code_literal">2</span>);          \
	x(<span class="code_literal">3</span>);
#<span class="code_keyword">else</span>
#define X_MACRO(x) \
	x(<span class="code_literal">1</span>);          \
	x(<span class="code_literal">2</span>);
#endif

<span class="code_comment">////////////////////////</span>

when _WIN32
	X_MACRO :: macro(x: macro(i: <span class="code_keyword">int</span>))
	{
		x(<span class="code_literal">1</span>);
		x(<span class="code_literal">2</span>);
		x(<span class="code_literal">3</span>);
	}
}

<span class="code_keyword">else</span>
{
	X_MACRO :: macro(x: macro(i: <span class="code_keyword">int</span>))
	{
		x(<span class="code_literal">1</span>);
		x(<span class="code_literal">2</span>);
	}
}
</div>
 Due to c-style sequence expressions being illegal in Otus, it is impossible to make a macro that defines memebers of structs and enums without implementing custom behaviour in a metaprogram. </div>
<div class="log_title_minimized tios200619" onclick="window.location.hash='#log@tios200619'"><a href="#log@tios200619">The Importance of Syntax</a></div><div class="log_date_minimized tios200619">2020/06/19</div>
<div class="log_content_minimized tios200619">
Before jumping into the sea of language design, I didn't care much for syntax. Sure, I had some pretty strong opinions on how I wanted my code to look. However, most of those where related to variable naming convention, indentation and languages that force a particular, *cough* OOP esque, style. Although I became more aware of how important syntax and naming is after starting to watch <a href="https://handmadehero.org/">Handmade Hero</a>, it was first when I began writing parsers that it dawned on me. I was writing the documentation for this horrible ad hoc syntax that puzzled, not only the people I showed it to, but also myself. It was not only hard on the eyes, but also a nightmare to parse. Afterwards I designed the language with parsing in mind, adding keywords and subtle details to remove unnecessary ambiguity. This was all fine and dandy for parsing, but it also became apparent that some parts of the language were much clearer and more natural when conveyed in a syntax that was not as easy to parse. It again became apparent that oversimplifying can, more often than not, add more complexity. An example of this is how <i>if</i> statements are parsed. One option would be to define an <i>if</i> statement as the keyword <i>if</i>, followed by an expression and then a statement. This is the definition I find to be the easiest to parse, and it may seem alright. However, it does introduce some inconsistency. 
<div class="code">
<span class="code_comment">// if expression statement allows this</span>
<span class="code_keyword">if</span> a == b <span class="code_function">DoStuff</span>();
<span class="code_comment">// but also this </span>
<span class="code_keyword">if</span> (a == b) <span class="code_function">DoStuff</span>();
</div>
 Now that may not seem like a huge problem, although it does add some visual inconsistency across a code base if the two styles are mixed. The problem lies in how that definition of an <i>if</i> statement compares to a "for" loop. Take a C style <i>for</i> loop. What would be a reasonable definition of how this <i>for</i> loop should look? Maybe the keyword <i>for</i> followed by a variable declaration, then an expression as the condition and a statement (since we are not crazy enough to allow assignment to be an expression) to be run after every loop. Something like this: 
<div class="code">
<span class="code_comment">// for statement expression statement statement</span>
<span class="code_keyword">for</span> <span class="code_keyword">int</span> i = <span class="code_literal">0</span> i &lt; <span class="code_literal">10</span> i += <span class="code_literal">1</span> <span class="code_function">DoStuff</span>();
</div>
 Well that looks like a mess. Lets add some parentheses and semicolons to separate the individual elements. 
<div class="code">
<span class="code_comment">// for (statement; expression; statement) statement</span>
<span class="code_keyword">for</span> (<span class="code_keyword">int</span> i = <span class="code_literal">0</span>; i &lt; <span class="code_literal">10</span>; i += <span class="code_literal">1</span>) <span class="code_function">DoStuff</span>();
</div>
 What we just did will not help the parser at all, but it is clearly more readable. Now, stop for a moment and think about how we treated the <i>for</i> loop differently from the <i>if</i> statement. The <i>for</i> loop needed some additional "fluff" to be readable, whilst the <i>if</i> statement did not. This may seem more like stating trivia than a glaring problem, but consider what a beginner might think of this. An obvious question would be "can I remove the parentheses around the <i>for</i>, like I can with the <i>if</i>"? The obvious answer would be "no, you can't", and that would be because the <i>for</i> requires parentheses, but the <i>if</i> does not. The only reason you may see parentheses in an <i>if</i> statement is because an expression surrounded by parentheses is still just an expression, and the <i>if</i> requires only an expression after the <i>if</i> keyword. So what? That seems like more of a problem with how the syntax is taught than an inherit problem with the syntax itself. That may be the case, but I would argue that the syntax design should take into account and eliminate such misconceptions. Why is that important? Lets look at assembly. <br> <br> I don't know about you, but I have a hard time understanding what a program does when written in assembly. More often than not do I end up having to go line by line and0 rewrite the assembly as "math with arrows". I usually have no problem with writing, but reading assembly is always a pain. Why is that? It may be because there are no operators, usually few variable names and a general lack of abstraction. Assembly is great, don't get me wrong, but it is horrible when it comes to quickly identifying what a piece of a program does and understanding how it works. Machine language is even worse, were you often have to resort to tables of opcodes to understand where the instructions are in a stream of 1's and 0's, what they do and how they affect each other. From what I've gathered, higher level languages were designed to mitigate this, <b>to make code more readable and easier to understand</b>. Then, if that is the reason why higher level languages exist, why do we keep making languages that are hard to read or have quirks that prompt questions? The reason for this is the same for any language, even natural languages, and that is because language design is hard and is often driven more by conventions than what makes the most sense. <br> <br> Another factor that should not be neglected is that people often say that syntax does not matter, semantics do. Even the creator of the programming language Jai has stated this numerous time in his <a href="https://www.youtube.com/playlist?list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO"> videos</a> about the language. This may not be true, at least not always, but I believe syntax is as important as semantics. Why? The syntax is what we use to convey the semantics, and if one does not fully understand the syntax, one cannot possibly understand the actual semantic information being conveyed. This is true both for programming languages and natural ones, and is the reason why "double speak" exists. An example of this would be answering the sentence "Have you eaten my lasagne", with "I ate my sandwich". This answer can both be the truth and a lie, depending on how one interprets it. The answer could be interpreted as "I ate my sandwich" with no additional information, but may be interpreted as "I did not eat your lasagne, only my sandwich" given the context. The answer could be remedied by adding an "only", but still goes to show how the same sentence can convey different meanings, if not crafted carefully. I therefore believe the best way to design a language is by <b>considering how a concept could be expressed, how that expression could be misinterpreted and how the concept and expression could be changed to mitigate this</b>. <br> <br> When designing Otus I have tried to take this into account and have ended up sinking hours into designing the <i>for</i> loop in this language. The challenge with <i>for</i> loops is that there is often a sharp distinction between how people think of them and how they are used, especially in C. The most common explanation, I find, for a <i>for</i> loop is a loop that executes a piece of code N times. This explanation leaves out all <i>for each</i> and <i>for as long as</i> style for loops, which I find to be more common and useful. One could kind of fix this problem by introducing new loop constructs and restricting their behaviour, but I have found that a looser definition of a <i>for</i> loops could be more useful. I would define a <i>for</i> loop along the lines of "a statement before a block of code that is will execute the block repeatedly as long as a condition holds, with the ability to specify a statement that is executed before the block, and one that is executed after every repetition and before the condition is checked, both statements are scoped to the block". Now definition is definitely wordy, and a bit loose. This might well be a stupid way to describe a <i>for</i> loop, but I think it does a better job of synergizing the syntax and semantics, and more closely reflects how <i>for</i> loops are actually used most of the time. I have therefore decided to double down on this and have ultimately decided that the language <b>will only feature one looping construct</b>, which is currently called a <i>for</i> loop. This loop behaves exactly like the definition I proposed, and was initially expressed like this: 
<div class="code">
<span class="code_comment">// for (statement; expression; statement) statement;</span>
<span class="code_keyword">for</span> (i : <span class="code_keyword">int</span> = <span class="code_literal">0</span>; i &lt; <span class="code_literal">10</span>; i += <span class="code_literal">1</span>) <span class="code_function">DoStuff</span>();
<span class="code_comment">// i : int = 0 is a variable declaration, equivalent to int i = 0 in C</span>
</div>
 Now, it is somewhat stupid to name this loop <i>for</i>, but I didn't find another name that would be a better fit. There are however some nasty problems with this, aside from the name. The problems do not lie in the definition or syntax, per se, but rather the weird surprises this type of loop can create. 
<div class="code">
<span class="code_comment">// This is a do {} while (0) in C</span>
<span class="code_keyword">for</span> (; <span class="code_literal">true</span>; <span class="code_keyword">break</span>) <span class="code_function">DoStuff</span>();
</div>
 After discovering this, and some other quirks, I tried rewriting them with an additional restriction on the loop. An example of this would be the rewritten <i>do while</i>: 
<div class="code">
<span class="code_comment">// for (variable_declaration; expression; assignment) statement;</span>
<span class="code_keyword">for</span> (; <span class="code_literal">true</span>; )
{
    <span class="code_keyword">break</span>;
}
</div>
 The intention of this loop is still not as clear as <i>do while</i>, and my decision of removing every loop construct except <i>for</i> may have been idiotic, but <b>I believe it might lead to a syntax that more closely resembles what is actually going on</b>. Again, oversimplifying something may often lead to more complexity. But if no one dares to do something that might be stupid, how will we ever evolve? <br> <br> EDIT:<br> The <i>for</i> keyword did not really fit, so I changed the name of the loop construct to <i>while</i> and introduced a new control structure, <i>for</i>, which serves the purpose of a for each style loop. </div>
</div>
</div>
</div>
</body>
</html>